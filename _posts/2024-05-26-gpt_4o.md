---
layout: article
title: GPT-4o 기본 개념
aside:
  toc: true
cover: /assets/ml/gpt_4o_thumbnail.jpg
excerpt: OpenAI에서 발표한 음성 기반 LLM 모델인 'GPT-4o'에 대해 알아보겠습니다.
---

# 1. 개요 

참고 문서: [GPT-4o 공식 문서](https://openai.com/index/hello-gpt-4o/)

GPT-4o(omni: 모든 것 )

<br>

- **지원되는 프롬프트** 
	- 텍스트 
	- 오디오 
	- 이미지 

<br>

<br>

# 2. 성능 비교 w. GPT 3.5 & GPT 4
- **추론 시간** 
	- 평균 320ms만에 오디오에 대답을 생성 
	- GPT 3.5는 평균 2.8초
	- GPT 4는 평균 5.4초 

<br> 

- **텍스트 생성 성능** 
	- 영문 텍스트 생성 성능은 GPT-4 Turbo와 비슷한 성능 
	- 비영어권의 텍스트 생성 성능은 크게 향상 
	
    <br>

	- GPT-4o와 GPT-4 Turbo가 가장 좋은 성능을 보임 
	- Claude 3와 Llama 400b 모델이 그 뒤를 이음 
	
![gpt_4o_performance_compare](/assets/ml/gpt_compare.webp)

<br>

- **오디오 모델 차이점 w. GPT 3.5 & GPT 4** 
	- 기존 모델들은 내부에서 TTS, STT 를 거치며 감정, 톤 등이 소멸 
	- GPT 4o는 전체 end2end 모델을 설계하여 감정, 톤 등을 그대로 보존 

![gpt_4o_audio](/assets/ml/gpt_4o_stt.webp)

<br>

<br>

# 3. 사용 방법 및 가격 

- **Availabilty** (2024년 5월 14일 기준)
	- API를 이용해 GPT-4o에 액세스 가능 
	- <u>현재는 text 및 vision 기능에만 접근 가능</u>
		- 가격은 GPT-4 Turbo에 비해 절반 수준 
	- <u>Audio 및 Video 기능은 추후 API에서 지원 예정</u>
	- web chatGPT plus에서도 아직은 음성 기능 사용 불가능 

<br>

- **Pricing**(2024년 5월 14일 기준)
	- GPT-4 Turbo의 절반 수준 
	- 1M input token에 5달러
	- 1M output token에 15달러 

![gpt_4o_pricing](/assets/ml/gpt_pricing.webp)


